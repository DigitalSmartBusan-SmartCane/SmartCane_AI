{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# 데이터 불러오기 및 처리 함수 정의\n",
    "def load_data(battery):\n",
    "    mat = loadmat(f'C:/LEE/batterydata/{battery}.mat')\n",
    "    dataset = []\n",
    "    capacity_data = []\n",
    "    counter = 0\n",
    "\n",
    "    for i in range(len(mat[battery][0, 0]['cycle'][0])):\n",
    "        row = mat[battery][0, 0]['cycle'][0, i]\n",
    "        if row['type'][0] == 'discharge':\n",
    "            capacity = row['data'][0][0]['Capacity'][0][0]\n",
    "            for j in range(len(row['data'][0][0]['Voltage_measured'][0])):\n",
    "                temperature_measured = row['data'][0][0]['Temperature_measured'][0][j]\n",
    "                current_measured = row['data'][0][0]['Current_measured'][0][j]\n",
    "                voltage_measured = row['data'][0][0]['Voltage_measured'][0][j]\n",
    "                dataset.append([counter + 1, temperature_measured, current_measured, voltage_measured, capacity])\n",
    "            capacity_data.append([counter + 1, capacity])\n",
    "            counter += 1\n",
    "\n",
    "    return pd.DataFrame(dataset, columns=['cycle', 'temperature_measured', 'current_measured', 'voltage_measured', 'capacity']), \\\n",
    "           pd.DataFrame(capacity_data, columns=['cycle', 'capacity'])\n",
    "\n",
    "# 데이터 불러오기\n",
    "data_B0005, capacity_B0005 = load_data('B0005')\n",
    "data_B0006, capacity_B0006 = load_data('B0006')\n",
    "data_B0007, capacity_B0007 = load_data('B0007')\n",
    "data_B0018, capacity_B0018 = load_data('B0018')\n",
    "\n",
    "# 공칭 용량 정의 및 SOH 계산\n",
    "initial_capacity = capacity_B0005['capacity'].iloc[0]  # B0005의 초기 용량을 공칭 용량으로 사용\n",
    "for capacity_data in [capacity_B0005, capacity_B0006, capacity_B0007, capacity_B0018]:\n",
    "    capacity_data['SOH'] = capacity_data['capacity'] / initial_capacity\n",
    "\n",
    "# Train data: B0005, B0006, B0018 | Test data: B0007\n",
    "train_data = pd.concat([data_B0005, data_B0006, data_B0018], ignore_index=True)\n",
    "test_data = data_B0007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 스케일링 (온도,전류,전압 만)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling (온도, 전류, 전압만 사용)\n",
    "scaler = MinMaxScaler()\n",
    "train_scaled = scaler.fit_transform(train_data[['temperature_measured', 'current_measured', 'voltage_measured']])\n",
    "test_scaled = scaler.transform(test_data[['temperature_measured', 'current_measured', 'voltage_measured']])\n",
    "\n",
    "# Sequence preparation for LSTM\n",
    "def create_sequences(data, sequence_length=20):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        x = data[i:i+sequence_length, :]  # Features: 온도, 전류, 전압\n",
    "        y = train_data['capacity'].iloc[i+sequence_length] / initial_capacity  # Capacity to SOH\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "sequence_length = 20\n",
    "X_train, y_train = create_sequences(train_scaled, sequence_length)\n",
    "X_test, y_test = create_sequences(test_scaled, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler_soh.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(scaler, 'scaler_soh.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 9ms/step - loss: 0.0337 - val_loss: 0.0044\n",
      "Epoch 2/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - loss: 0.0098 - val_loss: 0.0040\n",
      "Epoch 3/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - loss: 0.0073 - val_loss: 0.0051\n",
      "Epoch 4/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 10ms/step - loss: 0.0066 - val_loss: 0.0044\n",
      "Epoch 5/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 10ms/step - loss: 0.0062 - val_loss: 0.0071\n",
      "Epoch 6/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - loss: 0.0056 - val_loss: 0.0041\n",
      "Epoch 7/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 8/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 9ms/step - loss: 0.0038 - val_loss: 0.0051\n",
      "Epoch 9/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 9ms/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 10/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 11/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 9ms/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 12/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 10ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 13/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 11ms/step - loss: 0.0033 - val_loss: 0.0062\n",
      "Epoch 14/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 10ms/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 15/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 10ms/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 16/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 11ms/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 17/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 10ms/step - loss: 0.0030 - val_loss: 0.0049\n",
      "Epoch 18/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 10ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 19/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 10ms/step - loss: 0.0028 - val_loss: 0.0051\n",
      "Epoch 20/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 10ms/step - loss: 0.0027 - val_loss: 0.0052\n",
      "Epoch 21/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 10ms/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 22/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 10ms/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 23/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 10ms/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 24/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 10ms/step - loss: 0.0025 - val_loss: 0.0053\n",
      "Epoch 25/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 10ms/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 26/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - loss: 0.0024 - val_loss: 0.0050\n",
      "Epoch 27/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - loss: 0.0024 - val_loss: 0.0074\n",
      "Epoch 28/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 29/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 30/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 31/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - loss: 0.0023 - val_loss: 0.0056\n",
      "Epoch 32/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 33/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 10ms/step - loss: 0.0022 - val_loss: 0.0049\n",
      "Epoch 34/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 10ms/step - loss: 0.0022 - val_loss: 0.0046\n",
      "Epoch 35/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 10ms/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 36/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 37/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 38/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - loss: 0.0021 - val_loss: 0.0053\n",
      "Epoch 39/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 8ms/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 40/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 41/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 8ms/step - loss: 0.0019 - val_loss: 0.0043\n",
      "Epoch 42/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 43/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 10ms/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 44/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Epoch 45/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 12ms/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 46/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 10ms/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 47/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 8ms/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 48/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 49/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 50/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 10ms/step - loss: 0.0016 - val_loss: 0.0047\n",
      "Epoch 51/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Epoch 52/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 53/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 10ms/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 54/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 55/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 10ms/step - loss: 0.0015 - val_loss: 0.0040\n",
      "Epoch 56/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 10ms/step - loss: 0.0014 - val_loss: 0.0041\n",
      "Epoch 57/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 10ms/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 58/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 10ms/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 59/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 60/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 10ms/step - loss: 0.0012 - val_loss: 0.0049\n",
      "Epoch 61/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 10ms/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 62/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 10ms/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 63/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 64/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 10ms/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 65/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 10ms/step - loss: 0.0011 - val_loss: 0.0037\n",
      "Epoch 66/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 67/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0037\n",
      "Epoch 68/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - loss: 0.0010 - val_loss: 0.0038\n",
      "Epoch 69/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0037\n",
      "Epoch 70/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0037\n",
      "Epoch 71/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 11ms/step - loss: 0.0010 - val_loss: 0.0044\n",
      "Epoch 72/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - loss: 0.0010 - val_loss: 0.0045\n",
      "Epoch 73/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0034\n",
      "Epoch 74/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - loss: 9.9518e-04 - val_loss: 0.0038\n",
      "Epoch 75/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 11ms/step - loss: 0.0010 - val_loss: 0.0040\n",
      "Epoch 76/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 12ms/step - loss: 9.4202e-04 - val_loss: 0.0042\n",
      "Epoch 77/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 11ms/step - loss: 9.9045e-04 - val_loss: 0.0039\n",
      "Epoch 78/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 11ms/step - loss: 9.7050e-04 - val_loss: 0.0036\n",
      "Epoch 79/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 11ms/step - loss: 0.0010 - val_loss: 0.0048\n",
      "Epoch 80/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 13ms/step - loss: 9.1498e-04 - val_loss: 0.0036\n",
      "Epoch 81/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 12ms/step - loss: 9.9180e-04 - val_loss: 0.0041\n",
      "Epoch 82/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 83/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 11ms/step - loss: 8.7950e-04 - val_loss: 0.0034\n",
      "Epoch 84/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 85/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 11ms/step - loss: 9.5467e-04 - val_loss: 0.0039\n",
      "Epoch 86/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 11ms/step - loss: 9.1858e-04 - val_loss: 0.0041\n",
      "Epoch 87/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 11ms/step - loss: 8.9820e-04 - val_loss: 0.0037\n",
      "Epoch 88/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 11ms/step - loss: 9.5310e-04 - val_loss: 0.0035\n",
      "Epoch 89/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - loss: 9.7933e-04 - val_loss: 0.0037\n",
      "Epoch 90/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - loss: 8.8042e-04 - val_loss: 0.0038\n",
      "Epoch 91/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 13ms/step - loss: 9.6663e-04 - val_loss: 0.0035\n",
      "Epoch 92/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 10ms/step - loss: 8.9663e-04 - val_loss: 0.0042\n",
      "Epoch 93/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 11ms/step - loss: 8.5164e-04 - val_loss: 0.0035\n",
      "Epoch 94/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 11ms/step - loss: 8.5410e-04 - val_loss: 0.0036\n",
      "Epoch 95/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 10ms/step - loss: 8.7932e-04 - val_loss: 0.0035\n",
      "Epoch 96/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 10ms/step - loss: 8.9492e-04 - val_loss: 0.0041\n",
      "Epoch 97/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 10ms/step - loss: 8.2389e-04 - val_loss: 0.0039\n",
      "Epoch 98/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 10ms/step - loss: 8.4916e-04 - val_loss: 0.0039\n",
      "Epoch 99/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 10ms/step - loss: 8.1633e-04 - val_loss: 0.0039\n",
      "Epoch 100/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 10ms/step - loss: 8.2678e-04 - val_loss: 0.0036\n",
      "Epoch 101/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 10ms/step - loss: 7.8935e-04 - val_loss: 0.0040\n",
      "Epoch 102/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 161ms/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 103/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 11ms/step - loss: 7.8291e-04 - val_loss: 0.0032\n",
      "Epoch 104/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 10ms/step - loss: 8.1157e-04 - val_loss: 0.0036\n",
      "Epoch 105/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 10ms/step - loss: 8.5064e-04 - val_loss: 0.0037\n",
      "Epoch 106/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 10ms/step - loss: 8.0985e-04 - val_loss: 0.0037\n",
      "Epoch 107/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - loss: 8.0791e-04 - val_loss: 0.0038\n",
      "Epoch 108/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - loss: 8.6945e-04 - val_loss: 0.0034\n",
      "Epoch 109/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 11ms/step - loss: 7.3233e-04 - val_loss: 0.0039\n",
      "Epoch 110/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 11ms/step - loss: 7.5336e-04 - val_loss: 0.0039\n",
      "Epoch 111/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 12ms/step - loss: 8.3988e-04 - val_loss: 0.0035\n",
      "Epoch 112/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 13ms/step - loss: 7.5790e-04 - val_loss: 0.0039\n",
      "Epoch 113/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - loss: 7.2470e-04 - val_loss: 0.0037\n",
      "Epoch 114/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 12ms/step - loss: 7.9022e-04 - val_loss: 0.0037\n",
      "Epoch 115/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 12ms/step - loss: 7.2637e-04 - val_loss: 0.0036\n",
      "Epoch 116/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 12ms/step - loss: 7.1499e-04 - val_loss: 0.0036\n",
      "Epoch 117/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 14ms/step - loss: 8.0317e-04 - val_loss: 0.0037\n",
      "Epoch 118/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 10ms/step - loss: 7.1970e-04 - val_loss: 0.0034\n",
      "Epoch 119/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 10ms/step - loss: 7.6545e-04 - val_loss: 0.0030\n",
      "Epoch 120/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 16ms/step - loss: 8.0517e-04 - val_loss: 0.0036\n",
      "Epoch 121/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 13ms/step - loss: 6.9650e-04 - val_loss: 0.0033\n",
      "Epoch 122/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 13ms/step - loss: 7.1340e-04 - val_loss: 0.0035\n",
      "Epoch 123/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - loss: 7.5110e-04 - val_loss: 0.0040\n",
      "Epoch 124/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 13ms/step - loss: 7.7528e-04 - val_loss: 0.0035\n",
      "Epoch 125/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 15ms/step - loss: 7.4798e-04 - val_loss: 0.0039\n",
      "Epoch 126/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 16ms/step - loss: 7.6400e-04 - val_loss: 0.0037\n",
      "Epoch 127/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 11ms/step - loss: 7.5444e-04 - val_loss: 0.0036\n",
      "Epoch 128/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 13ms/step - loss: 6.9644e-04 - val_loss: 0.0036\n",
      "Epoch 129/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - loss: 7.5182e-04 - val_loss: 0.0036\n",
      "Epoch 130/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - loss: 8.6500e-04 - val_loss: 0.0038\n",
      "Epoch 131/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - loss: 7.2753e-04 - val_loss: 0.0034\n",
      "Epoch 132/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 11ms/step - loss: 8.1412e-04 - val_loss: 0.0038\n",
      "Epoch 133/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 12ms/step - loss: 8.3725e-04 - val_loss: 0.0040\n",
      "Epoch 134/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 13ms/step - loss: 7.5674e-04 - val_loss: 0.0032\n",
      "Epoch 135/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 13ms/step - loss: 6.6282e-04 - val_loss: 0.0037\n",
      "Epoch 136/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 13ms/step - loss: 7.2966e-04 - val_loss: 0.0036\n",
      "Epoch 137/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - loss: 7.0611e-04 - val_loss: 0.0035\n",
      "Epoch 138/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - loss: 7.0818e-04 - val_loss: 0.0037\n",
      "Epoch 139/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 9ms/step - loss: 6.5142e-04 - val_loss: 0.0035\n",
      "Epoch 140/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 9ms/step - loss: 6.9831e-04 - val_loss: 0.0032\n",
      "Epoch 141/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - loss: 6.5184e-04 - val_loss: 0.0036\n",
      "Epoch 142/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 13ms/step - loss: 6.9837e-04 - val_loss: 0.0038\n",
      "Epoch 143/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - loss: 6.6132e-04 - val_loss: 0.0036\n",
      "Epoch 144/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - loss: 7.2540e-04 - val_loss: 0.0034\n",
      "Epoch 145/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 13ms/step - loss: 8.1636e-04 - val_loss: 0.0037\n",
      "Epoch 146/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - loss: 6.9032e-04 - val_loss: 0.0039\n",
      "Epoch 147/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - loss: 6.5577e-04 - val_loss: 0.0036\n",
      "Epoch 148/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 10ms/step - loss: 6.6123e-04 - val_loss: 0.0039\n",
      "Epoch 149/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - loss: 7.9183e-04 - val_loss: 0.0040\n",
      "Epoch 150/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 12ms/step - loss: 6.4449e-04 - val_loss: 0.0036\n",
      "Epoch 151/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 10ms/step - loss: 6.6710e-04 - val_loss: 0.0039\n",
      "Epoch 152/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 10ms/step - loss: 6.7262e-04 - val_loss: 0.0037\n",
      "Epoch 153/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - loss: 6.9409e-04 - val_loss: 0.0038\n",
      "Epoch 154/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 14ms/step - loss: 6.5730e-04 - val_loss: 0.0039\n",
      "Epoch 155/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 13ms/step - loss: 6.1031e-04 - val_loss: 0.0036\n",
      "Epoch 156/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - loss: 6.8670e-04 - val_loss: 0.0033\n",
      "Epoch 157/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - loss: 7.1069e-04 - val_loss: 0.0038\n",
      "Epoch 158/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 13ms/step - loss: 6.2248e-04 - val_loss: 0.0035\n",
      "Epoch 159/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - loss: 6.6915e-04 - val_loss: 0.0039\n",
      "Epoch 160/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - loss: 6.4200e-04 - val_loss: 0.0036\n",
      "Epoch 161/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - loss: 6.1364e-04 - val_loss: 0.0037\n",
      "Epoch 162/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 8ms/step - loss: 6.2200e-04 - val_loss: 0.0034\n",
      "Epoch 163/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - loss: 6.0165e-04 - val_loss: 0.0038\n",
      "Epoch 164/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - loss: 6.3459e-04 - val_loss: 0.0036\n",
      "Epoch 165/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 11ms/step - loss: 6.0612e-04 - val_loss: 0.0036\n",
      "Epoch 166/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 9ms/step - loss: 5.7835e-04 - val_loss: 0.0042\n",
      "Epoch 167/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - loss: 6.5312e-04 - val_loss: 0.0039\n",
      "Epoch 168/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 10ms/step - loss: 6.1163e-04 - val_loss: 0.0037\n",
      "Epoch 169/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - loss: 5.9448e-04 - val_loss: 0.0041\n",
      "Epoch 170/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 10ms/step - loss: 6.0726e-04 - val_loss: 0.0037\n",
      "Epoch 171/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - loss: 7.3345e-04 - val_loss: 0.0038\n",
      "Epoch 172/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - loss: 6.2252e-04 - val_loss: 0.0037\n",
      "Epoch 173/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 12ms/step - loss: 6.3099e-04 - val_loss: 0.0040\n",
      "Epoch 174/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - loss: 5.9672e-04 - val_loss: 0.0039\n",
      "Epoch 175/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 11ms/step - loss: 6.0523e-04 - val_loss: 0.0039\n",
      "Epoch 176/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - loss: 5.9794e-04 - val_loss: 0.0039\n",
      "Epoch 177/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 12ms/step - loss: 5.7926e-04 - val_loss: 0.0037\n",
      "Epoch 178/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 14ms/step - loss: 5.5997e-04 - val_loss: 0.0036\n",
      "Epoch 179/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 14ms/step - loss: 6.0768e-04 - val_loss: 0.0044\n",
      "Epoch 180/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 10ms/step - loss: 6.4139e-04 - val_loss: 0.0038\n",
      "Epoch 181/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 13ms/step - loss: 6.1160e-04 - val_loss: 0.0046\n",
      "Epoch 182/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 12ms/step - loss: 6.5606e-04 - val_loss: 0.0037\n",
      "Epoch 183/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 13ms/step - loss: 6.2810e-04 - val_loss: 0.0040\n",
      "Epoch 184/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 10ms/step - loss: 6.1185e-04 - val_loss: 0.0037\n",
      "Epoch 185/200\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.3948e-04"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# LSTM 모델 정의\n",
    "model = Sequential([\n",
    "    LSTM(100, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)  # Output layer for SOH prediction\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "history = model.fit(X_train, y_train, epochs=200, batch_size=40, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('lstm_b000(5,6,7,18).keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m10,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,555</span> (127.17 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m32,555\u001b[0m (127.17 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,851</span> (42.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,851\u001b[0m (42.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,704</span> (84.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m21,704\u001b[0m (84.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 모델 파일 경로\n",
    "model_path = 'lstm_b000(5,6,7,18).keras'\n",
    "\n",
    "# 모델 불러오기\n",
    "model_soh = load_model(model_path)\n",
    "\n",
    "# 모델 요약 출력 (옵션)\n",
    "model_soh.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측 & 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1571/1571\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step\n",
      "Test RMSE for SOH: 0.13911533467674128\n",
      "Test R^2 Score for SOH: -1.0066590600259508\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Predict SOH on test set\n",
    "y_pred = model_soh.predict(X_test)\n",
    "\n",
    "# Calculate RMSE and R^2 for evaluation\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Test RMSE for SOH: {rmse}\")\n",
    "print(f\"Test R^2 Score for SOH: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실시간 예측?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "Predicted SOH in real-time: 327.7948303222656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "scaler = joblib.load('scaler_soh.pkl')\n",
    "\n",
    "def predict_soh_real_time(model, scaler, sequence):\n",
    "    # Scale sequence\n",
    "    sequence_scaled = scaler.transform(sequence)\n",
    "    sequence_scaled = np.expand_dims(sequence_scaled, axis=0)  # Reshape for LSTM\n",
    "    \n",
    "    # Predict SOH\n",
    "    predicted_soh = model.predict(sequence_scaled)[0][0]\n",
    "    return predicted_soh\n",
    "\n",
    "# Example usage: Provide a sequence of real-time data\n",
    "real_time_sequence = [\n",
    "    [23.8, 0.5, 0.02],  # 가장 오래된 측정값[온도,전류,전압]\n",
    "    [25.4, 0.5, 0.02],\n",
    "    [25.4, 0.5, 0.02],\n",
    "    [25.5, 0.6, 0.02],\n",
    "    [25.3, 0.4, 0.02],\n",
    "    [25.2, 0.5, 0.02],\n",
    "    [25.3, 0.5, 0.02],\n",
    "    [25.3, 0.5, 0.02],\n",
    "    [25.2, 0.4, 0.02],\n",
    "    [25.1, 0.6, 0.02],\n",
    "    [25.2, 0.5, 0.02],\n",
    "    [25.3, 0.5, 0.02],\n",
    "    [25.4, 0.4, 0.02],\n",
    "    [25.3, 0.5, 0.02],\n",
    "    [25.2, 0.5, 0.02],\n",
    "    [25.4, 0.6, 0.02],\n",
    "    [25.4, 0.5, 0.02],\n",
    "    [25.3, 0.5, 0.02]  # 가장 최신 측정값\n",
    "]\n",
    "\n",
    "predicted_soh = predict_soh_real_time(model_soh, scaler, real_time_sequence)\n",
    "print(f\"Predicted SOH in real-time: {predicted_soh}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
