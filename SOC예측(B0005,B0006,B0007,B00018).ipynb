{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## soc 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# 데이터 불러오기 함수 정의 (기존과 동일)\n",
    "def load_data(battery):\n",
    "    mat = loadmat(f'C:/LEE/batterydata/{battery}.mat')\n",
    "    dataset = []\n",
    "    capacity_data = []\n",
    "    counter = 0\n",
    "\n",
    "    for i in range(len(mat[battery][0, 0]['cycle'][0])):\n",
    "        row = mat[battery][0, 0]['cycle'][0, i]\n",
    "        if row['type'][0] == 'discharge':\n",
    "            capacity = row['data'][0][0]['Capacity'][0][0]\n",
    "            for j in range(len(row['data'][0][0]['Voltage_measured'][0])):\n",
    "                temperature_measured = row['data'][0][0]['Temperature_measured'][0][j]\n",
    "                current_measured = row['data'][0][0]['Current_measured'][0][j]\n",
    "                voltage_measured = row['data'][0][0]['Voltage_measured'][0][j]\n",
    "                dataset.append([counter + 1, temperature_measured, current_measured, voltage_measured, capacity])\n",
    "            capacity_data.append([counter + 1, capacity])\n",
    "            counter += 1\n",
    "\n",
    "    return pd.DataFrame(dataset, columns=['cycle', 'temperature_measured', 'current_measured', 'voltage_measured', 'capacity']), \\\n",
    "           pd.DataFrame(capacity_data, columns=['cycle', 'capacity'])\n",
    "\n",
    "# 데이터 로드\n",
    "data_B0005, capacity_B0005 = load_data('B0005')\n",
    "data_B0006, capacity_B0006 = load_data('B0006')\n",
    "data_B0007, capacity_B0007 = load_data('B0007')\n",
    "data_B0018, capacity_B0018 = load_data('B0018')\n",
    "\n",
    "# 공칭 용량 정의\n",
    "nominal_capacity = capacity_B0005['capacity'].iloc[0]\n",
    "\n",
    "# SOC 계산\n",
    "for data in [data_B0005, data_B0006, data_B0007, data_B0018]:\n",
    "    data['SOC'] = data['capacity'] / nominal_capacity  # SOC 비율로 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 스케일링 (온도,전류,전압 만)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling (온도, 전류, 전압)\n",
    "scaler = MinMaxScaler()\n",
    "train_data = pd.concat([data_B0005, data_B0006, data_B0018], ignore_index=True)\n",
    "test_data = data_B0007\n",
    "\n",
    "train_scaled = scaler.fit_transform(train_data[['temperature_measured', 'current_measured', 'voltage_measured']])\n",
    "test_scaled = scaler.transform(test_data[['temperature_measured', 'current_measured', 'voltage_measured']])\n",
    "\n",
    "# Sequence preparation for LSTM\n",
    "def create_sequences(data, soc_values, sequence_length=20):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        x = data[i:i+sequence_length, :]  # Features: 온도, 전류, 전압\n",
    "        y = soc_values[i + sequence_length]  # SOC 레이블\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "sequence_length = 20\n",
    "X_train, y_train = create_sequences(train_scaled, train_data['SOC'].values, sequence_length)\n",
    "X_test, y_test = create_sequences(test_scaled, test_data['SOC'].values, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler_soc.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(scaler, 'scaler_soc.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 0.0208 - val_loss: 0.0051\n",
      "Epoch 2/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - loss: 0.0072 - val_loss: 0.0030\n",
      "Epoch 3/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 0.0068 - val_loss: 0.0051\n",
      "Epoch 4/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 9ms/step - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 5/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 6/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 0.0055 - val_loss: 0.0069\n",
      "Epoch 7/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 8/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - loss: 0.0040 - val_loss: 0.0057\n",
      "Epoch 9/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - loss: 0.0036 - val_loss: 0.0055\n",
      "Epoch 10/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 0.0034 - val_loss: 0.0086\n",
      "Epoch 11/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - loss: 0.0033 - val_loss: 0.0053\n",
      "Epoch 12/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 13/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 0.0031 - val_loss: 0.0093\n",
      "Epoch 14/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - loss: 0.0029 - val_loss: 0.0051\n",
      "Epoch 15/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 8ms/step - loss: 0.0029 - val_loss: 0.0078\n",
      "Epoch 16/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 0.0029 - val_loss: 0.0050\n",
      "Epoch 17/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 18/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 0.0027 - val_loss: 0.0103\n",
      "Epoch 19/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - loss: 0.0027 - val_loss: 0.0048\n",
      "Epoch 20/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 0.0025 - val_loss: 0.0057\n",
      "Epoch 21/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 9ms/step - loss: 0.0025 - val_loss: 0.0071\n",
      "Epoch 22/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 0.0025 - val_loss: 0.0054\n",
      "Epoch 23/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - loss: 0.0024 - val_loss: 0.0050\n",
      "Epoch 24/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 25/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Epoch 26/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - loss: 0.0023 - val_loss: 0.0050\n",
      "Epoch 27/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 0.0022 - val_loss: 0.0059\n",
      "Epoch 28/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - loss: 0.0021 - val_loss: 0.0063\n",
      "Epoch 29/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - loss: 0.0021 - val_loss: 0.0076\n",
      "Epoch 30/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 31/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 32/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 8ms/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 33/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - loss: 0.0019 - val_loss: 0.0057\n",
      "Epoch 34/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 35/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 0.0018 - val_loss: 0.0046\n",
      "Epoch 36/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 0.0018 - val_loss: 0.0059\n",
      "Epoch 37/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 38/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 39/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 40/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 41/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 42/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 43/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 44/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 45/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 8ms/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 46/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 47/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 48/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 49/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 50/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 51/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - loss: 0.0013 - val_loss: 0.0044\n",
      "Epoch 52/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 53/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 54/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 55/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 56/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 57/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 9ms/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 58/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 59/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 60/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 61/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 0.0041\n",
      "Epoch 62/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 0.0037\n",
      "Epoch 63/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 0.0044\n",
      "Epoch 64/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 9.4313e-04 - val_loss: 0.0032\n",
      "Epoch 65/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 9.0170e-04 - val_loss: 0.0036\n",
      "Epoch 66/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 9ms/step - loss: 9.5740e-04 - val_loss: 0.0039\n",
      "Epoch 67/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 9ms/step - loss: 9.2200e-04 - val_loss: 0.0039\n",
      "Epoch 68/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 8.5166e-04 - val_loss: 0.0036\n",
      "Epoch 69/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 8.4506e-04 - val_loss: 0.0038\n",
      "Epoch 70/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 8.3627e-04 - val_loss: 0.0034\n",
      "Epoch 71/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - loss: 7.6538e-04 - val_loss: 0.0039\n",
      "Epoch 72/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 7.4158e-04 - val_loss: 0.0038\n",
      "Epoch 73/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 8.1599e-04 - val_loss: 0.0039\n",
      "Epoch 74/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 9ms/step - loss: 8.0111e-04 - val_loss: 0.0040\n",
      "Epoch 75/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - loss: 7.3167e-04 - val_loss: 0.0034\n",
      "Epoch 76/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 7.8214e-04 - val_loss: 0.0035\n",
      "Epoch 77/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 7.3625e-04 - val_loss: 0.0032\n",
      "Epoch 78/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - loss: 7.5749e-04 - val_loss: 0.0035\n",
      "Epoch 79/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - loss: 8.2678e-04 - val_loss: 0.0037\n",
      "Epoch 80/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - loss: 6.8955e-04 - val_loss: 0.0033\n",
      "Epoch 81/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - loss: 6.8322e-04 - val_loss: 0.0032\n",
      "Epoch 82/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 6.5414e-04 - val_loss: 0.0041\n",
      "Epoch 83/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 7.4991e-04 - val_loss: 0.0038\n",
      "Epoch 84/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 6.5841e-04 - val_loss: 0.0039\n",
      "Epoch 85/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 6.6335e-04 - val_loss: 0.0034\n",
      "Epoch 86/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 6.0972e-04 - val_loss: 0.0039\n",
      "Epoch 87/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 5.9299e-04 - val_loss: 0.0041\n",
      "Epoch 88/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 7.1795e-04 - val_loss: 0.0035\n",
      "Epoch 89/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 5.9841e-04 - val_loss: 0.0036\n",
      "Epoch 90/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - loss: 6.1735e-04 - val_loss: 0.0036\n",
      "Epoch 91/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 6.3901e-04 - val_loss: 0.0037\n",
      "Epoch 92/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 6.3523e-04 - val_loss: 0.0037\n",
      "Epoch 93/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 6.0392e-04 - val_loss: 0.0041\n",
      "Epoch 94/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 7.0684e-04 - val_loss: 0.0040\n",
      "Epoch 95/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 5.9106e-04 - val_loss: 0.0039\n",
      "Epoch 96/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 6.4476e-04 - val_loss: 0.0044\n",
      "Epoch 97/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 6.3935e-04 - val_loss: 0.0038\n",
      "Epoch 98/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 5.7940e-04 - val_loss: 0.0039\n",
      "Epoch 99/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - loss: 6.0578e-04 - val_loss: 0.0040\n",
      "Epoch 100/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 5.9608e-04 - val_loss: 0.0040\n",
      "Epoch 101/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 5.9210e-04 - val_loss: 0.0044\n",
      "Epoch 102/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 6.1427e-04 - val_loss: 0.0034\n",
      "Epoch 103/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 10ms/step - loss: 5.9989e-04 - val_loss: 0.0037\n",
      "Epoch 104/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 5.7476e-04 - val_loss: 0.0037\n",
      "Epoch 105/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 5.7114e-04 - val_loss: 0.0041\n",
      "Epoch 106/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 5.3963e-04 - val_loss: 0.0038\n",
      "Epoch 107/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 5.7629e-04 - val_loss: 0.0040\n",
      "Epoch 108/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - loss: 5.6699e-04 - val_loss: 0.0039\n",
      "Epoch 109/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 5.0874e-04 - val_loss: 0.0037\n",
      "Epoch 110/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 5.4822e-04 - val_loss: 0.0036\n",
      "Epoch 111/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - loss: 5.3865e-04 - val_loss: 0.0037\n",
      "Epoch 112/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 10ms/step - loss: 5.5641e-04 - val_loss: 0.0038\n",
      "Epoch 113/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 5.2598e-04 - val_loss: 0.0037\n",
      "Epoch 114/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 5.7067e-04 - val_loss: 0.0037\n",
      "Epoch 115/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 5.5172e-04 - val_loss: 0.0035\n",
      "Epoch 116/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 5.1627e-04 - val_loss: 0.0039\n",
      "Epoch 117/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - loss: 5.7631e-04 - val_loss: 0.0047\n",
      "Epoch 118/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 5.6349e-04 - val_loss: 0.0036\n",
      "Epoch 119/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - loss: 5.4089e-04 - val_loss: 0.0040\n",
      "Epoch 120/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 9ms/step - loss: 4.9656e-04 - val_loss: 0.0037\n",
      "Epoch 121/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 5.7592e-04 - val_loss: 0.0038\n",
      "Epoch 122/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - loss: 5.2189e-04 - val_loss: 0.0036\n",
      "Epoch 123/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - loss: 5.1953e-04 - val_loss: 0.0037\n",
      "Epoch 124/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - loss: 4.8835e-04 - val_loss: 0.0036\n",
      "Epoch 125/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 5.1122e-04 - val_loss: 0.0035\n",
      "Epoch 126/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 5.8420e-04 - val_loss: 0.0032\n",
      "Epoch 127/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - loss: 5.4571e-04 - val_loss: 0.0036\n",
      "Epoch 128/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - loss: 5.1184e-04 - val_loss: 0.0039\n",
      "Epoch 129/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 5.3875e-04 - val_loss: 0.0042\n",
      "Epoch 130/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - loss: 5.0328e-04 - val_loss: 0.0035\n",
      "Epoch 131/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 4.6221e-04 - val_loss: 0.0038\n",
      "Epoch 132/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 4.8975e-04 - val_loss: 0.0039\n",
      "Epoch 133/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 4.7087e-04 - val_loss: 0.0037\n",
      "Epoch 134/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 4.7903e-04 - val_loss: 0.0035\n",
      "Epoch 135/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 5.4271e-04 - val_loss: 0.0037\n",
      "Epoch 136/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - loss: 4.9837e-04 - val_loss: 0.0038\n",
      "Epoch 137/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - loss: 4.7427e-04 - val_loss: 0.0041\n",
      "Epoch 138/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - loss: 4.8637e-04 - val_loss: 0.0034\n",
      "Epoch 139/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 10ms/step - loss: 5.0023e-04 - val_loss: 0.0035\n",
      "Epoch 140/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - loss: 4.6901e-04 - val_loss: 0.0037\n",
      "Epoch 141/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 9ms/step - loss: 5.0963e-04 - val_loss: 0.0040\n",
      "Epoch 142/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - loss: 4.5535e-04 - val_loss: 0.0037\n",
      "Epoch 143/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 9ms/step - loss: 4.4440e-04 - val_loss: 0.0038\n",
      "Epoch 144/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - loss: 4.1697e-04 - val_loss: 0.0039\n",
      "Epoch 145/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - loss: 5.0386e-04 - val_loss: 0.0035\n",
      "Epoch 146/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 4.7881e-04 - val_loss: 0.0037\n",
      "Epoch 147/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - loss: 4.7315e-04 - val_loss: 0.0036\n",
      "Epoch 148/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - loss: 4.8889e-04 - val_loss: 0.0038\n",
      "Epoch 149/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 8ms/step - loss: 4.5156e-04 - val_loss: 0.0039\n",
      "Epoch 150/150\n",
      "\u001b[1m2709/2709\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - loss: 4.3525e-04 - val_loss: 0.0042\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# LSTM 모델 정의\n",
    "model_soc = Sequential([\n",
    "    LSTM(50, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dense(1)  # Output layer for SOC prediction\n",
    "])\n",
    "\n",
    "model_soc.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "history_soc = model_soc.fit(X_train, y_train, epochs=150, batch_size=40, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측 & 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1571/1571\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step\n",
      "Test RMSE for SOC: 0.1269269555016825\n",
      "Test R^2 Score for SOC: -1.3815093340269367\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Predict SOC on test set\n",
    "y_pred_soc = model_soc.predict(X_test)\n",
    "\n",
    "# Calculate RMSE and R^2 for evaluation\n",
    "rmse_soc = np.sqrt(mean_squared_error(y_test, y_pred_soc))\n",
    "r2_soc = r2_score(y_test, y_pred_soc)\n",
    "\n",
    "print(f\"Test RMSE for SOC: {rmse_soc}\")\n",
    "print(f\"Test R^2 Score for SOC: {r2_soc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_soc.save('lstm_soc_b000(5,6,7,18).keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m10,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,555</span> (127.17 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m32,555\u001b[0m (127.17 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,851</span> (42.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,851\u001b[0m (42.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,704</span> (84.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m21,704\u001b[0m (84.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 모델 파일 경로\n",
    "model_path = 'lstm_soc_b000(5,6,7,18).keras'\n",
    "\n",
    "# 모델 불러오기\n",
    "model_soc = load_model(model_path)\n",
    "\n",
    "# 모델 요약 출력 (옵션)\n",
    "model_soc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실시간 예측?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Predicted SOC in real-time: 202.5084991455078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "scaler = joblib.load('scaler_soc.pkl')\n",
    "\n",
    "def predict_soc_real_time(model, scaler, sequence):\n",
    "    # Scale sequence\n",
    "    sequence_scaled = scaler.transform(sequence)\n",
    "    sequence_scaled = np.expand_dims(sequence_scaled, axis=0)  # Reshape for LSTM\n",
    "    \n",
    "    # Predict SOC\n",
    "    predicted_soc = model.predict(sequence_scaled)[0][0]\n",
    "    return predicted_soc\n",
    "\n",
    "# Example usage: Provide a sequence of real-time data\n",
    "real_time_sequence = [\n",
    "    [23.7, 0.005, 0.02],  # 가장 오래된 측정값[온도,전류,전압] [23.7, 0.5, 3.7]\n",
    "    [23.7, 0.005, 0.02],\n",
    "    [23.7, 0.005, 0.02],\n",
    "    [23.7, 0.006, 0.02],\n",
    "    [23.7, 0.004, 0.02],\n",
    "    [23.7, 0.005, 0.02],\n",
    "    [23.7, 0.005, 0.02],\n",
    "    [23.7, 0.005, 0.02],\n",
    "    [23.7, 0.005, 0.02],\n",
    "    [23.8, 0.004, 0.02],\n",
    "    [23.8, 0.006, 0.02],\n",
    "    [23.8, 0.005, 0.02],\n",
    "    [23.8, 0.005, 0.02],\n",
    "    [23.8, 0.004, 0.02],\n",
    "    [23.8, 0.005, 0.02],\n",
    "    [23.8, 0.005, 0.02],\n",
    "    [23.8, 0.006, 0.02],\n",
    "    [23.8, 0.005, 0.02],\n",
    "    [23.8, 0.005, 0.02],\n",
    "    [23.8, 0.005, 0.02]  # 가장 최신 측정값\n",
    "]\n",
    "predicted_soc = predict_soc_real_time(model_soc, scaler, real_time_sequence)\n",
    "print(f\"Predicted SOC in real-time: {predicted_soc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
